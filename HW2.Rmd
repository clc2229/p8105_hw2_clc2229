---
title: "Homework 2"
author: "Christopher Crowe"
date: "September 25, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Problem 1

The piping in the following code chunk:

* reads in the data
* cleans the variable names
* chooses a selection of variables of interest
* converts the entry variable from character to logical

```{r subway data entry}
subway_data = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = "cccddcccccccccccccccccccccccddcc") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

As a result of the above code chunk, the data frame `subway_data` contains the following variables: `line`, `station_name`, `station_latitude`, `station_longitude`, `route1`, `route2`, `route3`, `route4`, `route5`, `route6`, `route7`, `route8`, `route9`, `route10`, `route11`, `entry`, `vending`, `entrance_type`, and `ada`. The data has been cleaned using the `janitor::clean_names()` function, which transforms all variable names to a format that is more preferable for data science purposes (e.g., `station_name` instead of `Station Name`). At this point, the data frame `subway_data` has the following dimensions: rows = `r nrow(subway_data)` and columns = `r ncol(subway_data)`. While the data have been somewhat cleaned, they are not tidy because we have the route variable spanning multiple columns.

Using this data, the following code can be used to gather the following information:

```{r distinct, eval = FALSE}
subway_data %>% 
  distinct(line, station_name) %>% 
  nrow()
```

* There are `r subway_data %>% distinct(line, station_name) %>% nrow()` distinct stations.

```{r ada, eval = FALSE}
subway_data %>%
  select(line, station_name, ada) %>% 
  filter(ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

* `r subway_data %>% select(line, station_name, ada) %>% filter(ada == TRUE) %>% distinct(line, station_name) %>% nrow()` stations are ADA compliant.


```{r vending, eval = FALSE}
subway_data %>% 
  select(line, station_name, vending, entry) %>% 
  filter(vending == "NO") %>% 
  summarize(round(mean(entry), digits = 2))
```

* `r subway_data %>% select(line, station_name, vending, entry) %>% filter(vending == "NO") %>% summarize(round(mean(entry), digits = 2))` of all entrances/exits without vending allow entrance.

The following code chunks reformat the data frame into a more tidy format.

```{r format}
formatted_subway_data = subway_data %>% 
  gather(key = route_number, value = route_name, route1:route11)
```

```{r A train, eval = FALSE}
formatted_subway_data %>% 
  select(line, station_name, route_name) %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

* There are `r formatted_subway_data %>% select(line, station_name, route_name) %>% filter(route_name == "A") %>% distinct(line, station_name) %>% nrow()` distinct stations that serve the A train.

```{r A train ADA, eval = FALSE}
formatted_subway_data %>% 
  select(line, station_name, route_name, ada) %>% 
  filter(route_name == "A" & ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

* Of these stations, `r formatted_subway_data %>% select(line, station_name, route_name, ada) %>% filter(route_name == "A" & ada == TRUE) %>% distinct(line, station_name) %>% nrow()` are ADA compliant.


## Problem 2

The piping in the following code chunk:

* reads in the Mr. Trash Wheel sheet
* omits columns with notes
* cleans the variable names
* omits rows without dumpster-specific data
* rounds the number of sports balls to the nearest integer and converts it to an interger variable

```{r trash data entry}
trash_wheel = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", "Mr. Trash Wheel", range = cellranger::cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))
```

The piping in the following code chunk:

* reads in the 2016 Precipitation and 2017 Precipitation sheets
* cleans the variable names
* omits rows without precipitation data
* adds a variable `year`

```{r}
precipitation_16 = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", "2016 Precipitation", range = cellranger::cell_cols("A:B")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(precipitation_in) & !is.na(x_1) & precipitation_in != "Month") %>% 
  rename(month_var = precipitation_in, total_precip_inches = x_1) %>% 
  mutate(year = "2016", total_precip_inches = round(as.double(total_precip_inches), digits = 2))

precipitation_17 = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", "2017 Precipitation", range = cellranger::cell_cols("A:B")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(precipitation_in) & !is.na(x_1) & precipitation_in != "Month") %>% 
  rename(month_var = precipitation_in, total_precip_inches = x_1) %>% 
  mutate(year = "2017", total_precip_inches = round(as.double(total_precip_inches), digits = 2))


precipitation_16_17 = bind_rows(precipitation_16, precipitation_17) %>%
  select(year, month_var, total_precip_inches) %>% 
  mutate(month_var = month.name[as.integer(month_var)])

```

```{r select data, include = FALSE}

## tests for inline code below

##select examples of key variables
precipitation_16_17 %>% 
  filter(total_precip_inches == 2.34) %>% 
  select(year)
precipitation_16_17 %>% 
  filter(total_precip_inches == 2.34) %>%
  select(month_var)
precipitation_16_17 %>% 
  filter(total_precip_inches == 2.34) %>%
  select(total_precip_inches)

## total precipitation in 2017
precipitation_16_17 %>% 
  filter(year == "2017") %>%
  select(total_precip_inches) %>% sum()

## median number of sports balls in 2016
trash_wheel %>% 
  filter(year == "2016") %>%
  summarize(median(sports_balls))


```


In the dataset for 2016, there are `r nrow(precipitation_16)` observations. In the dataset for 2017, there are `r nrow(precipitation_17)` observations. The key variables in the dataset are `year`, `month_var`, and `total_precip_inches`. `year` represents the year in which the data was recorded, such as `r precipitation_16_17 %>% filter(total_precip_inches == 2.34) %>% select(year)`. `month_var` represents the month in which the data was recorded, such as `r precipitation_16_17 %>% filter(total_precip_inches == 2.34) %>% select(month_var)`. `total_precip_inches` represents the amount of precipitation (inches) for a given recording period, such as `r precipitation_16_17 %>% filter(total_precip_inches == 2.34) %>% select(total_precip_inches)`. Using this data set, we can see that the total precipitation for 2017 so far is `r precipitation_16_17 %>% filter(year == "2017") %>% select(total_precip_inches) %>% sum()` inches. The median number of sports balls collected in 2016 was `r trash_wheel %>% filter(year == "2016") %>% summarize(median(sports_balls))`

## Problem 3


The piping in the following code chunk manipulates the BRFSS SMART2010 dataset so that:

* the variable names are clean
* we are only focusing on the "Overall Health" topic
* we have excluded variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation
* the responses (excellent to poor) are variables with the value of `data_value`
* there is a new variable that shows the proportion of responses that were "Excellent" or "Very Good"

```{r data setup}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("brfss_smart2010")


brfss_data = brfss_smart2010 %>%
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(proportion_excellent_vgood = (excellent + very_good) / 100)

```

```{r data questions, include = FALSE}

## tests for inline code below

## distinct locations
brfss_data %>% 
  distinct(locationdesc) %>% 
  nrow()
  
## number of states
brfss_data %>% 
  distinct(locationabbr) %>% 
  nrow()

## most frequently observed state
brfss_data %>% 
  count(locationabbr) %>% 
  arrange(desc(n)) %>% 
  select(locationabbr) %>% 
  head(1)

  
## median of "Excellent" in 2002
brfss_data %>% 
  filter(year == "2002") %>% 
  summarize(median(excellent, na.rm = TRUE))
 

## histogram
ggplot(brfss_data, aes(x = excellent)) +
  geom_histogram()

## scatterplot
brfss_data %>% 
  filter(locationdesc == "NY - New York County" | locationdesc == "NY - Queens County") %>% 
  ggplot(aes(x = year, y = excellent / 100, color = locationdesc)) +
  geom_point() 
  

```

There are `r brfss_data %>% distinct(locationdesc) %>% nrow()` distinct locations included in this dataset.There are `r brfss_data %>% distinct(locationabbr) %>% nrow()` distinct states represented, so we can assume all 50 states and Washington, DC are represented in this dataset. With `r brfss_data %>% count(locationabbr) %>% arrange(desc(n)) %>% select(n) %>% head(1)` observations, `r brfss_data %>% count(locationabbr) %>% arrange(desc(n)) %>% select(locationabbr) %>% head(1)` is the most observed state. The median of the "Excellent" response value in 2002 was `r brfss_data %>% filter(year == "2002") %>% summarize(median(excellent, na.rm = TRUE))`.

Here is a histogram of the "Excellent" response value in 2002. 

```{r histogram, echo = FALSE}
ggplot(brfss_data, aes(x = excellent)) + geom_histogram()

```

Here is a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r scatter, echo = FALSE}
brfss_data %>% 
  filter(locationdesc == "NY - New York County" | locationdesc == "NY - Queens County") %>% 
  ggplot(aes(x = year, y = excellent / 100, color = locationdesc)) +
  geom_point() 
```


